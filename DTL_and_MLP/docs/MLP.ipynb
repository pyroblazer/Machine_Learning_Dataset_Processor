{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penjelasan Implementasi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import library yang dibutuhkan program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neural_network import MLPClassifier # neural network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berikut merupakan fungsi sigmoid berdasarkan rumus\n",
    "![image.png](attachment:image.png)\n",
    "yang akan digunakan untuk perhitungan sigmoid di perceptron. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class Perceptron\n",
    "\n",
    "Dalam kelas perceptron, terdapat beberapa parameter, yaitu\n",
    "* data : list of data input yang akan diproses oleh perceptron\n",
    "* weight : list of weight dari seluruh data input\n",
    "* delta weight : list of delta weight dari seluruh data input\n",
    "* rate : learning rate dari perceptron\n",
    "\n",
    "init digunakan untuk menginisialisasi perceptron dengan data kosong, weight random, delta weight 0 dan learning rate sesuai yang diinput\n",
    "\n",
    "input_data digunakan untuk menginput data ke perceptron \n",
    "\n",
    "calc_sigmoid digunakan pada proses feed forward untuk mengkalkulasi net dari suatu layer neuron, lalu berdasarkan net itu, mengkalkulasi output dari layer neuron tersebut dengan fungsi sigmoid\n",
    "\n",
    "calc_delta digunakan saat backpropagation untuk menghitung delta dari suatu data berdasarkan rumus\n",
    "![calc_delta](images/delta_hidden.png)\n",
    "\n",
    "update_delta_weight saat backpropagation digunakan untuk memperbarui delta weight dari suatu data berdasarkan rumus\n",
    "![update_delta_weight](images/delta_weight.png)\n",
    "\n",
    "update_weight digunakan saat akhir batch untuk memperbarui weight dari suatu data berdasarkan rumus\n",
    "![update_weight](images/weight.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "\n",
    "    def __init__(self, rate, input_length):\n",
    "        self.data = []\n",
    "        self.weight = []\n",
    "        self.delta_weight = []\n",
    "        self.rate = rate\n",
    "\n",
    "        random_matrix = np.random.randn(1, input_length) * np.sqrt(1 / input_length)\n",
    "        for rand_array in random_matrix:\n",
    "            for rand_num in rand_array:\n",
    "                self.weight.append(rand_num)\n",
    "\n",
    "        # print(self.weight)\n",
    "\n",
    "        for inp in range(input_length):\n",
    "            self.delta_weight.append(0)\n",
    "\n",
    "\n",
    "    def input_data(self, data):\n",
    "        self.data = []\n",
    "        for datum in data:\n",
    "            self.data.append(datum)\n",
    "\n",
    "    def calc_sigmoid(self):\n",
    "        jumlah = 0\n",
    "        for i in range(len(self.data)):\n",
    "            jumlah += self.data[i] * self.weight[i]\n",
    "        self.output = sigmoid(jumlah)\n",
    "\n",
    "    #for backprop\n",
    "    def calc_delta(self, multiplier):\n",
    "        self.delta = self.output * (1-self.output) * multiplier\n",
    "\n",
    "    def update_delta_weight(self):\n",
    "        for i in range(len(self.delta_weight)):\n",
    "            self.delta_weight[i] += self.rate * self.delta * self.data[i]\n",
    "\n",
    "    # End of batch-size\n",
    "    def update_weight(self):\n",
    "        for i in range(len(self.weight)):\n",
    "            self.weight[i] += self.delta_weight[i]\n",
    "            self.delta_weight[i] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Class myMLP\n",
    "\n",
    "Dalam kelas myMLP, terdapat beberapa atribut yaitu\n",
    "* layers : list of data in a layer\n",
    "\n",
    "* hidden_layer_sizes : list dari jumlah hidden layer yang ada pada 1 layer\n",
    "* learning_rate : learning rate dari MLP\n",
    "* max_iter : jumlah iterasi maksimum dari MLP\n",
    "* error_treshold : batas error untuk mengakhiri proses MLP\n",
    "* batch_size : ukuran batch sebelum MLP mengupdate weight dari data\n",
    "\n",
    "fit digunakan untuk melakukan proses MLP berdasarkan input data dan target. Mulai dari inisialisasi data input sampai akhir dari \n",
    "\n",
    "update_all_weight digunakan untuk update semua weight dari seluruh perceptron dalam 1 layer\n",
    "\n",
    "calculate_error digunakan untuk mengkalkulasi error berdasarkan squared error function\n",
    "![calculate_error](images/calculate_error.png)\n",
    "\n",
    "initialize_perceptrons_in_layer digunakan untuk memasukkan perceptron ke dalam layer berdasarkan input jumlah perceptron dan jumlah input\n",
    "\n",
    "feed_forward digunakan untuk mengeksekusi feed forward. feed_forward akan mengkalkulasi net dan output dari suatu input data untuk satu layer, lalu memasukkan output sebagai input data untuk layer selanjutnya, dan mengulanginya untuk semua layer.\n",
    "\n",
    "backward_prop digunakan untuk mengeksekusi backward propagation.\n",
    "Untuk layer terakhir\n",
    "1. Pertama, backward_prop akan mengecek jika hasil kelas output sama dengan target, jika sama, maka valuenya 1, jika beda, maka valuenya 0. \n",
    "2. Kedua, backward_prop akan menghitung diff, yaitu perbedaaan antara output dan target. \n",
    "3. Ketiga, backward_prop akan menghitung delta dari satu perceptron pada layer terakhir. \n",
    "4. Keempat, backward_prop akan memperbarui delta_weight dari satu perceptron pada layer terakhir. \n",
    "5. Kelima, backward_prop akan menambahkan total error berdasarkan error dari satu perceptron pada layer terakhir. Proses ini diulangi untuk semua perceptron yang ada pada layer terakhir.\n",
    "Untuk hidden layer\n",
    "1. backward_prop akan mengkalkulasi diff, yaitu delta dikali weight, untuk satu perceptron di satu layer.\n",
    "2. backward_prop akan menghitung delta berdasarkan diff, untuk satu perceptron di satu layer.\n",
    "3. backward_prop akan menghitung delta weight, untuk satu perceptron di satu layer.\n",
    "4. backward prop akan mengulangi proses 1-3 untuk semua perceptron dalam satu layer.\n",
    "5. Lalu, backward_prop akan mengulangi proses 1-4 untuk semua layer yang ada kecuali yang terakhir (karena layer yang terakhir adalah layer output)\n",
    "\n",
    "predict digunakan untuk memprediksi nilai output dari data input\n",
    "\n",
    "show_model digunakan untuk menampilkan hasil dari proses MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myMLP:\n",
    "\n",
    "    def __init__(self, hidden_layer_sizes=[2, 3], learning_rate=0.001, max_iter=200, error_treshold=0.0001, batch_size=32):\n",
    "        # Attributes\n",
    "        self.layers = []\n",
    "        self.hidden_layer_sizes = hidden_layer_sizes\n",
    "        self.learning_rate = learning_rate\n",
    "        self.max_iter = max_iter\n",
    "        self.error_treshold = error_treshold\n",
    "        self.batch_size = batch_size\n",
    "        self.output_print = []\n",
    "\n",
    "\n",
    "    def fit(self, data_inputs, target):\n",
    "        self.data_inputs = data_inputs\n",
    "        self.target = target\n",
    "        self.classes = self.target.unique()\n",
    "\n",
    "        try:\n",
    "            #\n",
    "            number_of_inputs_from_previous_layer = len(self.data_inputs.columns)\n",
    "            # Initialize perceptrons in the hidden layers (from index 1)\n",
    "            for layer_idx in range(len(self.hidden_layer_sizes)):\n",
    "                # hidden_layer = Array of perceptrons\n",
    "                number_of_perceptrons_current_layer = self.hidden_layer_sizes[layer_idx]\n",
    "                hidden_layer = self.initialize_perceptrons_in_layer(number_of_perceptrons_current_layer, number_of_inputs_from_previous_layer)\n",
    "                number_of_inputs_from_previous_layer = self.hidden_layer_sizes[layer_idx]\n",
    "                self.layers.append(hidden_layer)\n",
    "\n",
    "            # Construct last (output) layer of perceptrons\n",
    "            number_of_perceptrons_last_layer = len(self.target.unique())\n",
    "            number_of_inputs_from_previous_layer = self.hidden_layer_sizes[-1]\n",
    "\n",
    "            output_layer = self.initialize_perceptrons_in_layer(number_of_perceptrons_last_layer, number_of_inputs_from_previous_layer)\n",
    "            self.layers.append(output_layer)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            # Construct last (output) layer of perceptrons\n",
    "            number_of_perceptrons_last_layer = len(self.target.unique())\n",
    "            number_of_inputs_from_previous_layer = len(self.data_inputs.columns)\n",
    "            output_layer = self.initialize_perceptrons_in_layer(number_of_perceptrons_last_layer, number_of_inputs_from_previous_layer)\n",
    "            self.layers.append(output_layer)\n",
    "\n",
    "        # Start feed forward and backward prop\n",
    "        number_of_rows = len(data_inputs)\n",
    "        for iteration in range(self.max_iter):\n",
    "            error_total = 0\n",
    "            for row in range(number_of_rows):\n",
    "                # print(\"row\")\n",
    "                # print(row)\n",
    "                self.feed_forward(row)\n",
    "\n",
    "                # Do backward prop then get error\n",
    "                error = self.backward_prop(row)\n",
    "                error_total += error\n",
    "\n",
    "                if (row % self.batch_size == 0):\n",
    "                    self.update_all_weights()\n",
    "\n",
    "            self.update_all_weights()\n",
    "\n",
    "            if (error_total < self.error_treshold):\n",
    "                break\n",
    "\n",
    "    def update_all_weights(self):\n",
    "        for layer in self.layers:\n",
    "            for perceptron in layer:\n",
    "                perceptron.update_weight()\n",
    "\n",
    "    def calculate_error(self, diff):\n",
    "        return 0.5 * (diff ** 2)\n",
    "\n",
    "    def initialize_perceptrons_in_layer (self, number_of_perceptrons, number_of_inputs):\n",
    "        layer = []\n",
    "        for idx_perceptron in range(number_of_perceptrons):\n",
    "            layer.append(Perceptron(self.learning_rate, number_of_inputs+1))\n",
    "        return layer\n",
    "\n",
    "    def feed_forward(self, row):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        # Initial inputs\n",
    "        for column in self.data_inputs.columns:\n",
    "            inputs.append(self.data_inputs[column][row])\n",
    "        inputs.append(1)\n",
    "\n",
    "        for layer_idx in range(len(self.layers)):\n",
    "            outputs.clear()\n",
    "            for perceptron in self.layers[layer_idx]:\n",
    "                perceptron.input_data(inputs)\n",
    "                perceptron.calc_sigmoid()\n",
    "                outputs.append(perceptron.output)\n",
    "\n",
    "            inputs.clear()\n",
    "            for output_data in outputs:\n",
    "                inputs.append(output_data)\n",
    "\n",
    "            inputs.append(1)\n",
    "\n",
    "    def backward_prop(self, row):\n",
    "        # Last layer\n",
    "        total_error = 0\n",
    "        for i in range(len(self.layers[-1])):\n",
    "            perceptron = self.layers[-1][i]\n",
    "            # Calculate diff (multiplier):\n",
    "            if self.classes[i] == self.target[row]:\n",
    "                result = 1\n",
    "            else:\n",
    "                result = 0\n",
    "            diff = result - perceptron.output\n",
    "            perceptron.calc_delta(diff)\n",
    "            perceptron.update_delta_weight()\n",
    "            total_error += self.calculate_error(diff)\n",
    "\n",
    "        # Hidden layers\n",
    "        for layer_idx in range(len(self.layers)-1): #banyaknya layer di layers, kecuali output layer\n",
    "            layer_size = len(self.layers[-layer_idx-2]) #banyaknya perceptron di layer itu\n",
    "            for perc_idx in range(layer_size): #untuk setiap perceptron di layer itu\n",
    "                diff = 0\n",
    "                for next_perceptron in self.layers[-layer_idx-1]:\n",
    "\n",
    "                    diff += next_perceptron.delta * next_perceptron.weight[perc_idx]\n",
    "                self.layers[-layer_idx-2][perc_idx].calc_delta(diff)\n",
    "                self.layers[-layer_idx-2][perc_idx].update_delta_weight()\n",
    "\n",
    "        return total_error\n",
    "\n",
    "    def predict(self, data_inputs):\n",
    "        inputs = []\n",
    "        outputs = []\n",
    "        predictions = []\n",
    "        for row in range(len(data_inputs)):\n",
    "            inputs.clear()\n",
    "            outputs.clear()\n",
    "            # Initial inputs\n",
    "            for column in data_inputs.columns:\n",
    "                inputs.append(data_inputs[column][row])\n",
    "            inputs.append(1)\n",
    "\n",
    "            for layer_idx in range(len(self.layers)):\n",
    "                outputs.clear()\n",
    "                for perceptron in self.layers[layer_idx]:\n",
    "                    perceptron.input_data(inputs)\n",
    "                    perceptron.calc_sigmoid()\n",
    "                    outputs.append(perceptron.output)\n",
    "                inputs.clear()\n",
    "                for output in outputs:\n",
    "                    inputs.append(output)\n",
    "                inputs.append(1)\n",
    "            idx = outputs.index(max(outputs))\n",
    "            predictions.append(self.classes[idx])\n",
    "        return predictions\n",
    "\n",
    "    def show_model(self, n=None):\n",
    "        self.output_print.clear()\n",
    "        for layer_idx in range(len(self.layers)):\n",
    "            for perceptron_idx in range(len(self.layers[layer_idx])):\n",
    "                for weight_idx in range(len(self.layers[layer_idx][perceptron_idx].weight)):\n",
    "                    if (weight_idx != len(self.layers[layer_idx][perceptron_idx].weight) - 1):\n",
    "                        self.output_print.append(str(\"Weight \" + str(weight_idx) + \"-\" + \"[\" + str(layer_idx) + \"][\" + str(perceptron_idx) + \"]: \" + str(self.layers[layer_idx][perceptron_idx].weight[weight_idx])))\n",
    "                    else:\n",
    "                        self.output_print.append(str(\"Bias \" + \"[\" + str(layer_idx) + \"][\" + str(perceptron_idx) + \"]: \" + str(self.layers[layer_idx][perceptron_idx].weight[weight_idx])))\n",
    "        if (n is None):\n",
    "            for output in self.output_print:\n",
    "                print(output)\n",
    "        else:\n",
    "            for i in range(n):\n",
    "                print(self.output_print[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hasil Eksekusi \n",
    "#### Show Model Menggunakan MyMLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (weights):\n",
      "Weight 0-[0][0]: -0.4580151997820117\n",
      "Weight 1-[0][0]: 0.26475744134482393\n",
      "Weight 2-[0][0]: 0.19413083964214112\n",
      "Weight 3-[0][0]: 0.9841209730053799\n",
      "Bias [0][0]: -0.16040992412317015\n",
      "Weight 0-[0][1]: -0.15087269481839113\n",
      "Weight 1-[0][1]: -0.17931566434434837\n",
      "Weight 2-[0][1]: -0.018014981301583903\n",
      "Weight 3-[0][1]: -0.026622233143138843\n",
      "Bias [0][1]: -0.12008585149949502\n",
      "Weight 0-[0][2]: 0.13131875213463318\n",
      "Weight 1-[0][2]: -0.8379367221340386\n",
      "Weight 2-[0][2]: 0.29490311522805884\n",
      "Weight 3-[0][2]: 0.16299160576162983\n",
      "Bias [0][2]: 1.0473466307064685\n",
      "Weight 0-[0][3]: 0.8460822463289981\n",
      "Weight 1-[0][3]: -0.39871982742906387\n",
      "Weight 2-[0][3]: -0.87480389570237\n",
      "Weight 3-[0][3]: -0.20236632895006668\n",
      "Bias [0][3]: 0.06628263122138826\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../iris.csv\")\n",
    "\n",
    "mlp = myMLP(max_iter = 400, hidden_layer_sizes=[100])\n",
    "\n",
    "inputs = data.drop('species', axis = 1)\n",
    "target = data['species']\n",
    "mlp.fit(inputs,target)\n",
    "\n",
    "print(\"Model (weights):\")\n",
    "mlp.show_model(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Penjelasan:\n",
    "\n",
    "myMLP dijalankan dengan max iteration = 400 dan dengan hidden layer sebanyak 1 layer.\n",
    "Pada hidden layer terdapat 100 perceptron.\n",
    "\n",
    "Penulisan weight memiliki format sebagai berikut:\n",
    "Weight <idx pada satu layer> - <idx layer> <idx perceptron>\n",
    "    \n",
    "Sebagai contoh,\n",
    "Weight 0 - [0][0], artinya weight tersebut adalah weight dengan index pertama pada layer 0 (tersambung dengan perceptron index pertama pada layer 0)\n",
    "    \n",
    "Weight 2 - [0][3], artinya weight tersebut adalah weight dengan index terakhir pada layer 0 (tersambung dengan perceptron index terakhir pada layer 0)\n",
    "    \n",
    "Sedangkan, penulisan weight bias memiliki format sebagai berikut:\n",
    "Bias [idx layer] [idx perceptron]\n",
    "    \n",
    "Sebagai contoh, Bias[0][3] = 0.066... , artinya weight bias pada perceptron index terakhir (idx = 3) pada layer 0 = 0.81...\n",
    "    \n",
    "\n",
    "Perhatikan bahwa penulisan weight dan bias dibatasi hingga 20 line saja."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pengukuran akurasi dengan split-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tested : 45\n",
      "True : 45\n",
      "Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([inputs, target], axis=1)\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "\n",
    "trainX = train[['sepal_length','sepal_width','petal_length','petal_width']] # taking the training data features\n",
    "trainY = train.species # output of our training data\n",
    "testX = test[['sepal_length','sepal_width','petal_length','petal_width']] # taking test data features\n",
    "testY = test.species   # output value of test data\n",
    "\n",
    "trainX = trainX.reset_index(drop=True)\n",
    "trainY = trainY.reset_index(drop=True)\n",
    "testX = testX.reset_index(drop=True)\n",
    "testY = testY.reset_index(drop=True)\n",
    "\n",
    "mlp2 = myMLP(max_iter = 400, hidden_layer_sizes=[100])\n",
    "mlp2.fit(trainX, trainY)\n",
    "prediction = mlp2.predict(testX)\n",
    "val = 0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i] == testY.values[i]:\n",
    "        val += 1\n",
    "print(\"Tested : \" + str(len(prediction)))\n",
    "print(\"True : \" + str(val))\n",
    "print(\"Accuracy : \" + str(val/len(prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tercapai akurasi 100% pada saat iterasi maksimal = 400 dan hidden layer sizes = 100.\n",
    "\n",
    "Jika max_iter dikurangi secara signifikan, akurasi akan menurun secara signifikan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perbandingan dengan hasil MLP sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:934: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model (weights)\n",
      "[array([[-1.33616139e-01, -3.50243731e-02,  4.82251878e-02,\n",
      "        -9.68239100e-03,  1.20706129e-01, -7.63841748e-05,\n",
      "        -1.00917962e-01,  4.46000430e-02, -1.01620347e-01,\n",
      "        -5.20572652e-02,  6.86854567e-02, -3.90038250e-02,\n",
      "         3.95165888e-02, -5.96953397e-02, -1.01279840e-01,\n",
      "        -1.07700806e-01, -8.60459367e-02, -7.39446813e-03,\n",
      "         1.04648626e-01, -4.38570644e-02, -3.77053053e-02,\n",
      "        -1.10598128e-01,  1.05199949e-01,  2.81923966e-02,\n",
      "         9.30548773e-02, -1.27449022e-01, -1.86417192e-02,\n",
      "        -4.68677197e-02, -1.02897751e-01,  9.46236401e-02,\n",
      "         6.59121747e-02,  9.18164693e-02, -4.07688013e-02,\n",
      "        -9.53157826e-02, -6.25917297e-02,  5.76587586e-02,\n",
      "         6.52339345e-02, -1.04505247e-01, -1.34404460e-02,\n",
      "        -4.91626267e-02, -9.18166980e-03,  9.14139216e-02,\n",
      "        -9.96553936e-02, -1.02545903e-01,  1.24502219e-02,\n",
      "         1.01853783e-01,  1.07400344e-01, -5.06523690e-02,\n",
      "         9.76630457e-02,  6.96672873e-03,  3.80044760e-02,\n",
      "         1.11104849e-01,  2.15791173e-02, -1.20153172e-01,\n",
      "         3.28209107e-02,  5.31677889e-02,  3.58102511e-02,\n",
      "         3.97139382e-02, -9.89587571e-02,  8.40725201e-02,\n",
      "        -1.33454701e-01, -1.22545912e-02,  9.02302573e-03,\n",
      "        -1.13254888e-01, -4.27010890e-02,  3.49501136e-02,\n",
      "         8.32552461e-02, -5.66562192e-02, -9.44055848e-02,\n",
      "        -1.72325066e-02, -1.32053494e-01,  1.03038193e-01,\n",
      "        -6.35822750e-03,  2.40450670e-02, -1.03755137e-02,\n",
      "         1.32811753e-01, -4.42738349e-02,  1.02954887e-01,\n",
      "         7.54868482e-02, -4.14652968e-02, -3.22494079e-02,\n",
      "        -6.02480579e-02,  2.60038544e-02,  5.33897964e-02,\n",
      "        -9.15557424e-02, -2.06779073e-02,  7.35529848e-02,\n",
      "        -7.58363282e-02, -1.12585809e-02, -1.04114795e-01,\n",
      "         8.34446636e-02,  5.04103591e-02, -3.20863128e-02,\n",
      "        -1.32651550e-01, -1.07330057e-01,  1.04186506e-01,\n",
      "         5.36445373e-02,  1.39986531e-01, -7.04923740e-02,\n",
      "        -5.83923386e-02],\n",
      "       [ 9.37814942e-02,  1.35553589e-01, -1.44830273e-01,\n",
      "        -1.02689339e-01, -6.89482005e-02,  1.16951706e-01,\n",
      "         8.94145984e-02, -7.72778736e-02, -4.51213481e-02,\n",
      "         8.80969843e-02, -1.28603400e-01,  8.27995975e-03,\n",
      "         2.85865154e-04, -1.08567176e-01, -9.66330817e-02,\n",
      "        -1.22136717e-01,  1.48325967e-01,  7.29863203e-02,\n",
      "         8.17193485e-02,  1.13242214e-02,  8.89455919e-02,\n",
      "        -5.32548344e-02, -9.24563850e-02,  8.39398924e-02,\n",
      "         4.36204140e-02, -3.82634944e-02, -1.00087744e-01,\n",
      "        -6.79261678e-02,  1.43084212e-01,  8.80140465e-02,\n",
      "         5.53444618e-02, -1.29817104e-01,  1.01433849e-02,\n",
      "         5.10251751e-03, -3.91890571e-02, -2.61526796e-02,\n",
      "         1.83244661e-03,  1.27629592e-01,  7.33758575e-02,\n",
      "        -7.95255794e-03,  1.07022845e-01, -1.03415555e-01,\n",
      "        -9.64850394e-02,  5.09126610e-02, -9.21882751e-02,\n",
      "         4.31202144e-02,  1.00067168e-01,  9.30567723e-02,\n",
      "         8.57755856e-02, -1.13237966e-01, -1.36422103e-01,\n",
      "         9.16203063e-02,  1.10868885e-02,  3.42839716e-02,\n",
      "        -5.62661437e-02,  2.91872029e-02,  1.12081417e-01,\n",
      "        -9.23092559e-02,  1.28189776e-02, -4.49420583e-02,\n",
      "         5.54374935e-02,  8.04291048e-02, -5.78298313e-04,\n",
      "         4.57169797e-02, -1.11355788e-01,  3.87235804e-03,\n",
      "        -7.97659711e-02, -5.37843409e-02,  2.69611505e-02,\n",
      "         1.11417570e-01, -1.15016804e-01, -4.57400408e-02,\n",
      "        -1.37606930e-01,  1.30665507e-01,  1.31692367e-01,\n",
      "         2.02577230e-02,  4.28015102e-02,  1.35696861e-01,\n",
      "        -3.54103852e-02, -9.52489883e-02,  9.24045505e-02,\n",
      "        -3.32358966e-02, -6.15966655e-02,  9.58663486e-02,\n",
      "         1.50401651e-03,  1.76681410e-02,  1.11233875e-01,\n",
      "         3.98305159e-02,  8.12971355e-02, -3.16962618e-02,\n",
      "        -3.42314870e-02, -4.89427044e-02,  4.03722202e-03,\n",
      "         3.19437062e-03, -1.91333243e-02, -2.41803326e-04,\n",
      "        -1.59384259e-02, -1.06668151e-01,  1.07107989e-01,\n",
      "         1.78945645e-02],\n",
      "       [-5.23031469e-02,  1.49748238e-01,  1.64149593e-01,\n",
      "        -1.00827201e-01,  1.19428235e-01,  6.44166363e-02,\n",
      "         5.82124339e-02,  3.79508403e-02,  5.37949692e-03,\n",
      "         1.28349708e-01,  4.11160849e-02,  1.27572089e-01,\n",
      "        -1.38156756e-01, -9.62500776e-02,  6.79168387e-02,\n",
      "        -5.94624544e-02,  7.75445011e-02,  3.18940122e-02,\n",
      "        -1.24773657e-01,  3.01831848e-02,  1.97130638e-02,\n",
      "        -1.31955085e-01,  1.01418127e-01,  1.40325540e-01,\n",
      "        -1.11253948e-01,  6.45914634e-03,  8.84317190e-03,\n",
      "         5.53349612e-02, -1.27670977e-01,  4.56446199e-02,\n",
      "        -8.72143472e-02,  1.46618967e-01, -3.46482396e-02,\n",
      "         7.21402760e-02,  5.79117051e-02,  1.56739272e-01,\n",
      "         1.15419016e-01,  1.01222703e-01,  7.65197218e-02,\n",
      "         6.45497727e-02, -1.27554235e-01,  8.94118906e-02,\n",
      "        -7.40859920e-02,  1.09100245e-01,  1.73708716e-01,\n",
      "         6.44707310e-02,  1.97687960e-02,  1.39472421e-01,\n",
      "        -1.77250944e-01, -8.53036090e-02,  1.95521958e-02,\n",
      "        -1.46764261e-01, -7.83178668e-02, -3.42661070e-02,\n",
      "        -2.84731683e-05, -3.85664639e-02,  3.44415351e-02,\n",
      "         1.31373836e-01,  1.33469347e-01,  1.13468896e-01,\n",
      "        -3.59834867e-02, -5.13090339e-02, -1.10808239e-02,\n",
      "         1.10639212e-01,  3.97212988e-03, -1.14859812e-01,\n",
      "        -1.04818857e-01, -8.19788253e-02,  1.02433203e-01,\n",
      "         6.02468248e-02, -5.82851555e-02, -1.29766381e-01,\n",
      "         1.44805813e-01,  1.29972636e-02, -9.54730380e-02,\n",
      "        -4.25264228e-02, -9.57468216e-03, -3.66918492e-02,\n",
      "        -1.29371506e-01, -8.42057419e-02, -9.30626657e-02,\n",
      "         1.53142392e-02,  7.50131486e-02,  4.48438061e-02,\n",
      "        -4.74903355e-02,  4.59928027e-03, -6.21868914e-02,\n",
      "         7.96744378e-02,  8.94838904e-02,  1.12549866e-02,\n",
      "        -9.65403417e-02, -5.58266632e-02, -3.45178648e-02,\n",
      "        -8.98994372e-03, -1.33355412e-01, -9.00433910e-02,\n",
      "        -7.94857254e-02, -1.69711796e-02,  4.61577329e-02,\n",
      "        -1.19613521e-01],\n",
      "       [ 8.86338621e-02, -7.98147412e-02,  2.25185065e-03,\n",
      "         1.03636059e-01,  1.29052230e-01, -3.66465016e-02,\n",
      "        -8.33562243e-02,  7.66861812e-02, -7.34953394e-02,\n",
      "         1.29548217e-01,  8.17844396e-03,  1.70530745e-02,\n",
      "         4.12470683e-02,  1.27569081e-01,  5.47940899e-02,\n",
      "         5.22179291e-02,  5.59320166e-02,  7.80066197e-02,\n",
      "        -1.29403155e-01, -1.08135741e-01, -1.77867582e-02,\n",
      "        -1.09031528e-01, -1.41822026e-02,  1.44215558e-01,\n",
      "         8.21688957e-02, -8.27536502e-02,  4.74230807e-02,\n",
      "        -2.19013241e-02, -1.14100684e-01, -7.95929499e-02,\n",
      "         2.10059135e-02,  4.06786646e-02, -1.61347833e-01,\n",
      "         1.61560919e-01,  8.03780169e-02,  1.28524672e-01,\n",
      "         5.68611988e-02, -7.58601248e-02, -1.13367821e-02,\n",
      "         5.35767912e-02,  1.16838637e-01, -1.39427380e-01,\n",
      "         6.71461858e-02,  7.37267116e-02,  1.47681252e-01,\n",
      "        -4.19494138e-02,  4.54354915e-02, -6.66978055e-02,\n",
      "         7.17986278e-02,  9.12118375e-02,  1.02402390e-01,\n",
      "        -1.34412154e-01, -1.39578565e-02, -9.83308057e-02,\n",
      "         8.21680956e-02,  3.55896209e-03, -8.56889818e-03,\n",
      "         3.11575565e-02,  9.63181642e-02, -6.74655358e-02,\n",
      "         8.90585575e-02,  1.09725385e-02,  2.54719984e-02,\n",
      "        -7.50132343e-02, -3.36580216e-02,  1.12059158e-01,\n",
      "        -4.63874086e-02,  3.21695692e-02, -1.03856236e-01,\n",
      "         5.42636708e-02,  9.52275036e-02, -8.45064637e-02,\n",
      "        -6.59156232e-03, -8.94442288e-02,  9.69824164e-02,\n",
      "         3.19208130e-02,  6.81031497e-02,  1.16697366e-01,\n",
      "        -4.88569545e-02, -1.57917142e-01, -9.03694606e-02,\n",
      "         5.00690929e-02, -5.89899480e-02, -6.40209770e-02,\n",
      "         8.46859088e-02,  1.93139437e-02,  4.12589931e-02,\n",
      "         1.30395888e-01, -2.14058848e-02,  7.56371341e-02,\n",
      "         5.63337056e-02, -1.01224131e-01,  4.80848639e-02,\n",
      "         9.26819349e-02, -1.36714433e-01,  7.89862068e-02,\n",
      "        -3.23768601e-02,  3.02879173e-02,  1.01476471e-01,\n",
      "         9.86020736e-02]]), array([[ 0.1481441 ,  0.00023823, -0.08082764],\n",
      "       [-0.00524986, -0.02719348,  0.15296155],\n",
      "       [-0.11290847,  0.12301274,  0.16165956],\n",
      "       [-0.06539985, -0.02538939, -0.11276902],\n",
      "       [-0.18998317,  0.02361355,  0.01522803],\n",
      "       [ 0.04560925, -0.00462034,  0.01827196],\n",
      "       [-0.09712628,  0.01183217,  0.01944952],\n",
      "       [-0.06291478, -0.10289724, -0.00455211],\n",
      "       [-0.05274308,  0.06160766,  0.01757871],\n",
      "       [-0.03778551,  0.11089828,  0.09222522],\n",
      "       [-0.05349318,  0.04293873,  0.09696779],\n",
      "       [-0.16695196,  0.06032891, -0.10879442],\n",
      "       [ 0.06576411, -0.07219356, -0.06375982],\n",
      "       [-0.07440857, -0.09982947, -0.07291405],\n",
      "       [ 0.00685995, -0.07953362,  0.05554299],\n",
      "       [ 0.00582561,  0.05825835, -0.14364387],\n",
      "       [ 0.10619977, -0.10371955,  0.07162158],\n",
      "       [ 0.03368356,  0.01405857, -0.03633552],\n",
      "       [ 0.0228131 , -0.04275387, -0.0538263 ],\n",
      "       [ 0.09213816, -0.09514057, -0.07257393],\n",
      "       [-0.05686386,  0.05996716,  0.06101178],\n",
      "       [ 0.02630145,  0.08634756, -0.04207181],\n",
      "       [-0.07198289, -0.13079856,  0.02918375],\n",
      "       [-0.03196111,  0.00481947,  0.17534064],\n",
      "       [ 0.14556706, -0.0080051 ,  0.08640325],\n",
      "       [-0.02176073, -0.06638072,  0.03431103],\n",
      "       [ 0.08349283,  0.05055934,  0.10221932],\n",
      "       [-0.13505366, -0.05048524, -0.11520632],\n",
      "       [ 0.16228555, -0.04176301, -0.15162263],\n",
      "       [ 0.12159169, -0.01281928,  0.13020736],\n",
      "       [ 0.00641424, -0.00207028, -0.09639481],\n",
      "       [-0.03185177,  0.10275222,  0.11056633],\n",
      "       [ 0.10969882,  0.04409121, -0.14139588],\n",
      "       [-0.14315357, -0.05642213,  0.10047116],\n",
      "       [-0.1235011 ,  0.09208738, -0.09348634],\n",
      "       [-0.08237247,  0.14956073,  0.07288095],\n",
      "       [-0.13435734,  0.02871379,  0.00463298],\n",
      "       [ 0.03212873, -0.02344018, -0.03121357],\n",
      "       [-0.02037139, -0.08774981,  0.03023091],\n",
      "       [ 0.10087611,  0.08972951,  0.15020597],\n",
      "       [ 0.08442622,  0.02456789, -0.06048257],\n",
      "       [-0.07001419,  0.03598947, -0.08812937],\n",
      "       [-0.04294455, -0.06579706,  0.08134688],\n",
      "       [ 0.03226261,  0.04927135,  0.11607822],\n",
      "       [-0.1884712 , -0.0194347 ,  0.0226406 ],\n",
      "       [ 0.06698278,  0.03193716,  0.02262093],\n",
      "       [ 0.01242109, -0.03156196,  0.00953641],\n",
      "       [ 0.02378176,  0.0899362 ,  0.05754467],\n",
      "       [ 0.13194135, -0.01174126, -0.09747695],\n",
      "       [ 0.10058605, -0.01115986, -0.09297648],\n",
      "       [-0.13789614,  0.05514036, -0.08926619],\n",
      "       [ 0.0958675 , -0.08510117,  0.0350948 ],\n",
      "       [-0.03682307,  0.11610338, -0.10520191],\n",
      "       [ 0.07669525,  0.12117022,  0.000516  ],\n",
      "       [-0.10537696,  0.05258149, -0.00291499],\n",
      "       [ 0.06320359, -0.03259375,  0.0535115 ],\n",
      "       [-0.05257929, -0.03476337,  0.07272525],\n",
      "       [-0.10727766, -0.11445443, -0.00025773],\n",
      "       [-0.09092882, -0.01931687,  0.00283942],\n",
      "       [-0.05370129,  0.04764688,  0.13229946],\n",
      "       [-0.04428932,  0.08111557, -0.06070506],\n",
      "       [ 0.09067749, -0.09376258, -0.05796432],\n",
      "       [ 0.05290586, -0.08480192, -0.06544467],\n",
      "       [ 0.0834161 ,  0.00884131,  0.05614385],\n",
      "       [ 0.11094778,  0.06984625,  0.13292976],\n",
      "       [ 0.0577791 , -0.00966622, -0.02313205],\n",
      "       [ 0.0868936 ,  0.13013617, -0.11390125],\n",
      "       [-0.01149137,  0.10650986,  0.1091891 ],\n",
      "       [-0.05444805, -0.04929145,  0.01578421],\n",
      "       [-0.02940944,  0.00817042, -0.0528983 ],\n",
      "       [ 0.11097045,  0.08428431, -0.03467668],\n",
      "       [ 0.1142138 ,  0.11401727, -0.06026515],\n",
      "       [-0.03241378,  0.10702345,  0.04232459],\n",
      "       [-0.07997711, -0.03082107, -0.01724237],\n",
      "       [ 0.13377468,  0.09530191,  0.0097189 ],\n",
      "       [ 0.07676369,  0.04109889,  0.09940951],\n",
      "       [ 0.02016433,  0.03767682,  0.13182412],\n",
      "       [ 0.09431134, -0.11224699, -0.04814479],\n",
      "       [ 0.08154868, -0.02934367, -0.04153121],\n",
      "       [ 0.15805616, -0.08463907, -0.15362384],\n",
      "       [ 0.13422094, -0.08038235, -0.09495108],\n",
      "       [-0.0976453 , -0.00528675,  0.07311241],\n",
      "       [-0.1184132 ,  0.01496462, -0.11878782],\n",
      "       [-0.10637579,  0.07553458,  0.06735721],\n",
      "       [ 0.12258968,  0.09128006, -0.11928909],\n",
      "       [ 0.06714685, -0.0535149 , -0.10547752],\n",
      "       [ 0.03448191, -0.00800762, -0.05532775],\n",
      "       [-0.1019939 , -0.05376311, -0.10041879],\n",
      "       [-0.03123928, -0.13722057, -0.00995035],\n",
      "       [-0.03637477,  0.00036137, -0.05044525],\n",
      "       [ 0.09895205, -0.00028504, -0.07415717],\n",
      "       [ 0.05541134,  0.05115232,  0.1024192 ],\n",
      "       [-0.07590858, -0.05509342,  0.05791516],\n",
      "       [ 0.09247741,  0.00325746, -0.03373142],\n",
      "       [ 0.07083829, -0.0979683 ,  0.08436193],\n",
      "       [ 0.10939848,  0.12029662,  0.07201355],\n",
      "       [ 0.10131779, -0.13212416, -0.0875268 ],\n",
      "       [ 0.06436172, -0.08137931,  0.11692865],\n",
      "       [-0.01994484,  0.10414631, -0.00514827],\n",
      "       [ 0.00109249,  0.05257932, -0.1476733 ]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"../iris.csv\")\n",
    "target = data[['species']].replace(['Iris-setosa','Iris-versicolor','Iris-virginica'],[0,1,2])\n",
    "newData = data.drop('species', axis = 1)\n",
    "\n",
    "\n",
    "clf1 = MLPClassifier(solver='sgd', batch_size=32, alpha=0, momentum=0, nesterovs_momentum=False, activation='logistic', max_iter=400, hidden_layer_sizes=(100))\n",
    "clf1.fit(newData,target)\n",
    "\n",
    "print(\"Model (weights)\")\n",
    "print(clf1.coefs_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh cara membaca weight\n",
    "-1.33616139e-01 adalah weight pertama yang tersambung pada perceptron pertama pada hidden layer pertama.\n",
    "-3.50243731e-02 adalah weight pertama yang tersambung pada perceptron kedua pada  hidden layer pertama.\n",
    "4.82251878e-02 adalah weight pertama yang tersambung pada perceptron ketiga pada hidden layer pertama.\n",
    "-9.68239100e-03 adalah weight pertama yang tersambung pada perceptron keempat pada hidden layer pertama.\n",
    "\n",
    "1.20706129e-01 adalah weight kedua yang tersambung pada perceptron pertama pada hidden layer pertama.\n",
    "4.46000430e-02 adalah weight kedua yang tersambung pada perceptron kedua pada hidden layer kedua.\n",
    "\n",
    "dan seterusnya...\n",
    "\n",
    "Setiap layer dibedakan dengan index matriks. Contohnya, weight dari input layer ke hidden layer pertama terkandung dalam matriks pertama (idx = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan bahwa weight yang disebutkan berbeda dengan MyMLP karena cara inisialisasi weight yang berbeda. \n",
    "Sumber scikit-learn menginisiasi weight: <br> \n",
    "#### Glorot, X. & Bengio, Y.. (2010). Understanding the difficulty of training deep feedforward neural networks. Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, in PMLR 9:249-256"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pengukuran Akurasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the Multi-layer Perceptron is: 0.6444444444444445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (400) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([newData, target], axis=1)\n",
    "train, test = train_test_split(df, test_size=0.3)\n",
    "trainX = train[['sepal_length','sepal_width','petal_length','petal_width']] # taking the training data features\n",
    "trainY = train.species #output of our training data\n",
    "testX = test[['sepal_length','sepal_width','petal_length','petal_width']] # taking test data features\n",
    "testY = test.species   #output value of test data\n",
    "\n",
    "clf2 = MLPClassifier(solver='sgd', batch_size=32, alpha=0, momentum=0, nesterovs_momentum=False, activation='logistic', max_iter=400, hidden_layer_sizes=(100))\n",
    "clf2.fit(trainX, trainY)\n",
    "\n",
    "prediction = clf2.predict(testX)\n",
    "print('The accuracy of the Multi-layer Perceptron is:',metrics.accuracy_score(prediction,testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhatikan bahwa akurasi scikit learn dalam mengklasifikasikan data kalah dibandingkan MyMLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
